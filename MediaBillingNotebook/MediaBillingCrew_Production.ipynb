{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26481ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# IMPORTS AND DEPENDENCIES\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "# File reading libraries\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# CrewAI imports\n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from crewai.tools import tool\n",
    "\n",
    "print(\"‚úÖ All dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecffc0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ENVIRONMENT SETUP\n",
    "# ============================================\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"‚ö†Ô∏è  Warning: OPENAI_API_KEY not found in environment\")\n",
    "    print(\"   Please add it to your .env file\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API key loaded\")\n",
    "\n",
    "# Initialize LLM\n",
    "llm = LLM(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0.1  # Low temperature for consistent extraction\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLM initialized: gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9675dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CANONICAL INVOICE SCHEMA DEFINITION\n",
    "# ============================================\n",
    "CANONICAL_SCHEMA_DOC = \"\"\"\n",
    "You MUST output JSON ARRAY matching this structure:\n",
    " \n",
    "[\n",
    "  \"invoice_header\": {\n",
    "    \"invoice_number\": string or null,\n",
    "    \"vendor_name\": string or null,\n",
    "    \"invoice_date\": string or null,          // YYYY-MM-DD if possible\n",
    "    \"billing_start_date\": string or null,    // YYYY-MM-DD if possible\n",
    "    \"billing_end_date\": string or null,      // YYYY-MM-DD if possible\n",
    "    \"currency\": string or null,           // YYYY-MM-DD if possible\n",
    "    \"gross_revenue\": number or null,\n",
    "    \"discount_amount\": number or null,\n",
    "    \"discount_percent\": number or null,\n",
    "    \"tax\": number or null,\n",
    "    \"line_items\": [\n",
    "        {\n",
    "          \"line_id\": integer,\n",
    "          \"campaign_name\": string or null,\n",
    "          \"campaign_id\": string or null,\n",
    "          \"insertion_order_ID\": string or null, // may be same for different segments\n",
    "          \"start_date\": string or null,          // YYYY-MM-DD if possible\n",
    "          \"end_date\": string or null,            // YYYY-MM-DD if possible\n",
    "          \"planned impressions\": number or null,\n",
    "          \"billed impressions\": number or null,\n",
    "          \"views\": number or null,               // complete views, video views, completed clicks, clicks conversions, etc. choose the closest\n",
    "          \"gross_revenue\": number or null,\n",
    "          \"net_revenue\": number or null,\n",
    "          \"discount_amount\": number or null,\n",
    "          \"discount_percent\": number or null,\n",
    "          \"profit\": number or null,\n",
    "          \"rate_type\": string or null,           // CPM, CPC, CPV, Flat, etc.\n",
    "          \"rate\": number or null,\n",
    "        }\n",
    "    ]\n",
    "    },\n",
    "  ]\n",
    " \n",
    "RULES:\n",
    "- If a value is not present in the invoice, use null.\n",
    "- If only one type of revenue is present, store it in gross_revenue and leave net_revenue null (or vice versa if clearly net).\n",
    "- Discounts can be explicit (discount column) or implicit (difference between gross and net) ‚Äî explain in notes if inferred.\n",
    "- Profit = revenue - cost, if not directly provided.\n",
    "- Be conservative: do NOT invent numbers if they are not in the invoice.\n",
    "- Campaign ID can be the segment ID\n",
    "- Insertion order id can not be same as Campaign ID. Insertion order id can be a short form\n",
    "\"\"\"\n",
    "print(\"‚úÖ Canonical schema defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FILE READING FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def read_pdf_content(pdf_path: str, max_pages: int = 5) -> str:\n",
    "    \"\"\"Extract text from PDF files with OCR fallback for image-based PDFs.\"\"\"\n",
    "    try:\n",
    "        pages_text = []\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                if i >= max_pages:\n",
    "                    break\n",
    "                text = page.extract_text() or \"\"\n",
    "                \n",
    "                # If no text extracted, try OCR on the page image\n",
    "                if not text.strip():\n",
    "                    try:\n",
    "                        # Convert page to image and use OCR\n",
    "                        page_image = page.to_image(resolution=300).original\n",
    "                        text = pytesseract.image_to_string(page_image)\n",
    "                    except pytesseract.TesseractNotFoundError:\n",
    "                        text = \"\"\"[ERROR: Tesseract OCR not installed]\n",
    "                        \n",
    "To install Tesseract:\n",
    "‚Ä¢ macOS: brew install tesseract\n",
    "‚Ä¢ Ubuntu/Debian: sudo apt-get install tesseract-ocr\n",
    "‚Ä¢ Windows: Download from https://github.com/UB-Mannheim/tesseract/wiki\"\"\"\n",
    "                    except Exception as ocr_error:\n",
    "                        text = f\"[OCR failed for page {i+1}: {str(ocr_error)}]\"\n",
    "                \n",
    "                if text:\n",
    "                    pages_text.append(f\"--- Page {i+1} ---\\n{text}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(pages_text) if pages_text else \"No text extracted from PDF\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading PDF: {str(e)}\"\n",
    "\n",
    "\n",
    "def read_image_content(image_path: str) -> str:\n",
    "    \"\"\"Extract text from images using OCR.\"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text.strip() if text.strip() else \"No text extracted from image\"\n",
    "    except pytesseract.TesseractNotFoundError:\n",
    "        return \"\"\"ERROR: Tesseract OCR is not installed.\n",
    "        \n",
    "To install Tesseract:\n",
    "‚Ä¢ macOS: brew install tesseract\n",
    "‚Ä¢ Ubuntu/Debian: sudo apt-get install tesseract-ocr\n",
    "‚Ä¢ Windows: Download from https://github.com/UB-Mannheim/tesseract/wiki\n",
    "\n",
    "After installation, restart your kernel.\"\"\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading image: {str(e)}\"\n",
    "\n",
    "\n",
    "def read_excel_content(excel_path: str, sheet_name=None, max_rows=50) -> Dict[str, Any]:\n",
    "    \"\"\"Read Excel file and return structured preview.\"\"\"\n",
    "    try:\n",
    "        excel_file = pd.ExcelFile(excel_path)\n",
    "        \n",
    "        # Determine which sheet to read\n",
    "        if sheet_name is not None:\n",
    "            sheets = [sheet_name]\n",
    "        else:\n",
    "            # Read first sheet only for production\n",
    "            sheets = [excel_file.sheet_names[0]]\n",
    "        \n",
    "        result = {\n",
    "            \"file_name\": Path(excel_path).name,\n",
    "            \"total_sheets\": len(excel_file.sheet_names),\n",
    "            \"sheet_names\": excel_file.sheet_names,\n",
    "            \"data\": {}\n",
    "        }\n",
    "        \n",
    "        for sheet in sheets:\n",
    "            df = pd.read_excel(excel_path, sheet_name=sheet)\n",
    "            \n",
    "            # Clean column names\n",
    "            df.columns = [\n",
    "                str(c).strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "                for c in df.columns\n",
    "            ]\n",
    "            \n",
    "            # Limit rows\n",
    "            preview_df = df.head(max_rows)\n",
    "            \n",
    "            result[\"data\"][sheet] = {\n",
    "                \"total_rows\": len(df),\n",
    "                \"columns\": list(df.columns),\n",
    "                \"preview\": preview_df.to_dict(orient=\"records\"),\n",
    "                \"preview_text\": preview_df.to_string(index=False, max_colwidth=30)\n",
    "            }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "def read_csv_content(csv_path: str, max_rows=50) -> Dict[str, Any]:\n",
    "    \"\"\"Read CSV file and return structured preview.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Clean column names\n",
    "        df.columns = [\n",
    "            str(c).strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "            for c in df.columns\n",
    "        ]\n",
    "        \n",
    "        preview_df = df.head(max_rows)\n",
    "        \n",
    "        return {\n",
    "            \"file_name\": Path(csv_path).name,\n",
    "            \"total_rows\": len(df),\n",
    "            \"columns\": list(df.columns),\n",
    "            \"preview\": preview_df.to_dict(orient=\"records\"),\n",
    "            \"preview_text\": preview_df.to_string(index=False, max_colwidth=30)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "def read_text_content(text_path: str) -> str:\n",
    "    \"\"\"Read plain text files.\"\"\"\n",
    "    try:\n",
    "        with open(text_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading text file: {str(e)}\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ File reading functions created (with OCR support for images and image-based PDFs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# INVOICE CONTEXT BUILDER\n",
    "# ============================================\n",
    "\n",
    "def build_invoice_context(file_path: str, max_rows: int = 50) -> str:\n",
    "    \"\"\"\n",
    "    Build formatted context from any invoice file type.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to invoice file\n",
    "        max_rows: Maximum rows for tabular data\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string with invoice content\n",
    "    \"\"\"\n",
    "    file_path_obj = Path(file_path)\n",
    "    \n",
    "    if not file_path_obj.exists():\n",
    "        return f\"ERROR: File not found: {file_path}\"\n",
    "    \n",
    "    suffix = file_path_obj.suffix.lower()\n",
    "    \n",
    "    output = []\n",
    "    output.append(f\"FILE: {file_path_obj.name}\")\n",
    "    output.append(\"=\" * 70)\n",
    "    \n",
    "    # PDF files\n",
    "    if suffix == '.pdf':\n",
    "        output.append(\"TYPE: PDF Invoice\")\n",
    "        output.append(\"\\nCONTENT:\")\n",
    "        content = read_pdf_content(str(file_path))\n",
    "        output.append(content)\n",
    "    \n",
    "    # Excel files\n",
    "    elif suffix in ['.xlsx', '.xls']:\n",
    "        output.append(\"TYPE: Excel Spreadsheet\")\n",
    "        data = read_excel_content(str(file_path), max_rows=max_rows)\n",
    "        \n",
    "        if \"error\" in data:\n",
    "            output.append(f\"\\nERROR: {data['error']}\")\n",
    "        else:\n",
    "            output.append(f\"\\nSheets: {', '.join(data['sheet_names'])}\")\n",
    "            for sheet_name, sheet_data in data['data'].items():\n",
    "                output.append(f\"\\n--- Sheet: {sheet_name} ---\")\n",
    "                output.append(f\"Total Rows: {sheet_data['total_rows']}\")\n",
    "                output.append(f\"Columns: {', '.join(sheet_data['columns'])}\")\n",
    "                output.append(f\"\\nData Preview (first {max_rows} rows):\")\n",
    "                output.append(sheet_data['preview_text'])\n",
    "    \n",
    "    # CSV files\n",
    "    elif suffix == '.csv':\n",
    "        output.append(\"TYPE: CSV File\")\n",
    "        data = read_csv_content(str(file_path), max_rows=max_rows)\n",
    "        \n",
    "        if \"error\" in data:\n",
    "            output.append(f\"\\nERROR: {data['error']}\")\n",
    "        else:\n",
    "            output.append(f\"\\nTotal Rows: {data['total_rows']}\")\n",
    "            output.append(f\"Columns: {', '.join(data['columns'])}\")\n",
    "            output.append(f\"\\nData Preview (first {max_rows} rows):\")\n",
    "            output.append(data['preview_text'])\n",
    "    \n",
    "    # Image files\n",
    "    elif suffix in ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']:\n",
    "        output.append(\"TYPE: Image File (OCR Extraction)\")\n",
    "        output.append(\"\\nCONTENT:\")\n",
    "        content = read_image_content(str(file_path))\n",
    "        output.append(content)\n",
    "    \n",
    "    # Text files\n",
    "    elif suffix == '.txt':\n",
    "        output.append(\"TYPE: Text Invoice\")\n",
    "        output.append(\"\\nCONTENT:\")\n",
    "        content = read_text_content(str(file_path))\n",
    "        output.append(content)\n",
    "    \n",
    "    else:\n",
    "        output.append(f\"ERROR: Unsupported file type: {suffix}\")\n",
    "    \n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Invoice context builder created (supports PDF, Excel, CSV, Images, Text)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CREWAI AGENT DEFINITION\n",
    "# ============================================\n",
    "\n",
    "invoice_extraction_agent = Agent(\n",
    "    role='Media Invoice Data Extraction Specialist',\n",
    "    goal='Extract structured financial and delivery data from media invoices into canonical JSON format',\n",
    "    backstory=\"\"\"You are an expert in media billing and invoice processing. \n",
    "    You understand advertising metrics (impressions, views, clicks), financial terms \n",
    "    (revenue, costs, discounts, profit), and how to extract data accurately from \n",
    "    various invoice formats including OCR-extracted text from images and scanned PDFs.\n",
    "    \n",
    "    You are skilled at handling noisy or imperfectly formatted text from OCR, identifying\n",
    "    patterns, and extracting meaningful data even when formatting is inconsistent.\n",
    "    You always follow the canonical schema strictly and never invent data - you use null \n",
    "    for missing values. When dealing with OCR text, you intelligently parse tables and \n",
    "    structured data even when spacing or alignment is imperfect.\"\"\",\n",
    "    llm=llm,\n",
    "    tools=[],  # No tools needed - direct file reading\n",
    "    verbose=True,\n",
    "    allow_delegation=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Invoice extraction agent created (optimized for OCR text handling)\")\n",
    "print(f\"   Role: {invoice_extraction_agent.role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de5d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TASK CREATION FUNCTION\n",
    "# ============================================\n",
    "\n",
    "def create_extraction_task(file_path: str, max_rows: int = 50) -> Task:\n",
    "    \"\"\"\n",
    "    Create extraction task with invoice context and schema.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to invoice file\n",
    "        max_rows: Maximum rows for tabular data\n",
    "    \n",
    "    Returns:\n",
    "        Task configured for invoice extraction\n",
    "    \"\"\"\n",
    "    # Build context from file\n",
    "    context_str = build_invoice_context(file_path, max_rows=max_rows)\n",
    "    \n",
    "    description = f\"\"\"\n",
    "Extract structured invoice data from the provided file and map it to the canonical schema.\n",
    "\n",
    "**CANONICAL SCHEMA:**\n",
    "{CANONICAL_SCHEMA_DOC}\n",
    "\n",
    "**INVOICE DATA:**\n",
    "{context_str}\n",
    "\n",
    "**INSTRUCTIONS:**\n",
    "1. Identify invoice header information (vendor, dates, totals, currency)\n",
    "2. Extract all line items with sequential line_id starting from 1\n",
    "3. Map financial metrics (revenue, costs, discounts, profit)\n",
    "4. Map delivery metrics (impressions, views, clicks)\n",
    "5. Calculate implicit discounts if gross and net revenue differ\n",
    "6. Use null for missing values - DO NOT INVENT DATA\n",
    "7. For OCR-extracted text: Look for patterns and table structures even if spacing/formatting is imperfect\n",
    "8. Handle OCR artifacts gracefully (e.g., misread characters, spacing issues)\n",
    "9. Add clarifications to 'notes' field if needed or if OCR quality affected extraction\n",
    "10. Return ONLY valid JSON - no markdown, no explanations\n",
    "\n",
    "**OUTPUT REQUIREMENT:**\n",
    "Return a single valid JSON object following the canonical schema exactly.\n",
    "\"\"\".strip()\n",
    "    \n",
    "    task = Task(\n",
    "        description=description,\n",
    "        agent=invoice_extraction_agent,\n",
    "        expected_output=\"Valid JSON object with invoice_header, line_items array, and notes field\"\n",
    "    )\n",
    "    \n",
    "    return task\n",
    "\n",
    "\n",
    "print(\"‚úÖ Task creation function defined (with OCR-specific instructions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7289a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# MAIN EXTRACTION FUNCTION\n",
    "# ============================================\n",
    "\n",
    "def extract_invoice_data(file_path: str, max_rows: int = 50) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract structured invoice data from any supported file format.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to invoice file (PDF, Excel, CSV, or text)\n",
    "        max_rows: Maximum rows to process from tabular files\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with extracted invoice data in canonical format\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìÑ EXTRACTING INVOICE DATA\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"File: {Path(file_path).name}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Create task\n",
    "    task = create_extraction_task(file_path, max_rows=max_rows)\n",
    "    \n",
    "    # Create crew with single agent\n",
    "    crew = Crew(\n",
    "        agents=[invoice_extraction_agent],\n",
    "        tasks=[task],\n",
    "        process=Process.sequential,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Execute extraction\n",
    "    result = crew.kickoff()\n",
    "    result_str = str(result).strip()\n",
    "    \n",
    "    # Parse JSON from result\n",
    "    try:\n",
    "        parsed = json.loads(result_str)\n",
    "    except json.JSONDecodeError:\n",
    "        # Try to extract JSON from response\n",
    "        start = result_str.find(\"{\")\n",
    "        end = result_str.rfind(\"}\")\n",
    "        \n",
    "        if start != -1 and end != -1 and start < end:\n",
    "            json_str = result_str[start : end + 1]\n",
    "            try:\n",
    "                parsed = json.loads(json_str)\n",
    "            except json.JSONDecodeError as e:\n",
    "                return {\n",
    "                    \"error\": \"Failed to parse JSON response\",\n",
    "                    \"details\": str(e),\n",
    "                    \"raw_response\": result_str[:500]\n",
    "                }\n",
    "        else:\n",
    "            return {\n",
    "                \"error\": \"No JSON object found in response\",\n",
    "                \"raw_response\": result_str[:500]\n",
    "            }\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚úÖ EXTRACTION COMPLETE\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return parsed\n",
    "\n",
    "\n",
    "print(\"‚úÖ Main extraction function created\")\n",
    "print(\"   Usage: result = extract_invoice_data('invoice.xlsx')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# VALIDATION FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def validate_extracted_data(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Validate extracted data against canonical schema.\n",
    "    \n",
    "    Returns:\n",
    "        Validation report with errors and warnings\n",
    "    \"\"\"\n",
    "    validation = {\n",
    "        \"valid\": True,\n",
    "        \"errors\": [],\n",
    "        \"warnings\": []\n",
    "    }\n",
    "    \n",
    "    # Check top-level structure\n",
    "    if \"invoice_header\" not in data:\n",
    "        validation[\"valid\"] = False\n",
    "        validation[\"errors\"].append(\"Missing 'invoice_header' field\")\n",
    "    \n",
    "    if \"line_items\" not in data:\n",
    "        validation[\"valid\"] = False\n",
    "        validation[\"errors\"].append(\"Missing 'line_items' field\")\n",
    "    elif not isinstance(data[\"line_items\"], list):\n",
    "        validation[\"valid\"] = False\n",
    "        validation[\"errors\"].append(\"'line_items' must be an array\")\n",
    "    \n",
    "    # Check header has minimal info\n",
    "    if \"invoice_header\" in data:\n",
    "        header = data[\"invoice_header\"]\n",
    "        if not header.get(\"invoice_number\") and not header.get(\"vendor_name\"):\n",
    "            validation[\"warnings\"].append(\"Missing both invoice_number and vendor_name\")\n",
    "        if not header.get(\"currency\"):\n",
    "            validation[\"warnings\"].append(\"Currency not specified\")\n",
    "    \n",
    "    # Check line items have IDs\n",
    "    if \"line_items\" in data and isinstance(data[\"line_items\"], list):\n",
    "        for idx, item in enumerate(data[\"line_items\"]):\n",
    "            if \"line_id\" not in item:\n",
    "                validation[\"warnings\"].append(f\"Line item at index {idx} missing 'line_id'\")\n",
    "    \n",
    "    return validation\n",
    "\n",
    "\n",
    "print(\"‚úÖ Validation function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b7d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXPORT FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def save_to_json(data: Dict[str, Any], output_path: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Save extracted data to JSON file.\n",
    "    \n",
    "    Args:\n",
    "        data: Extracted invoice data\n",
    "        output_path: Custom output path (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Path to saved file\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_path = f\"data/invoice_extract_{timestamp}.json\"\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "\n",
    "def convert_to_dataframe(data: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert line items to pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data: Extracted invoice data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with line items and header info\n",
    "    \"\"\"\n",
    "    if \"line_items\" not in data or not data[\"line_items\"]:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.DataFrame(data[\"line_items\"])\n",
    "    \n",
    "    # Add header fields to each row\n",
    "    if \"invoice_header\" in data:\n",
    "        header = data[\"invoice_header\"]\n",
    "        for key in [\"invoice_number\", \"vendor_name\", \"invoice_date\", \"currency\"]:\n",
    "            if key in header:\n",
    "                df[key] = header[key]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"‚úÖ Export functions created\")\n",
    "print(\"   ‚Ä¢ save_to_json() - Save to JSON file\")\n",
    "print(\"   ‚Ä¢ convert_to_dataframe() - Convert to DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7323706f",
   "metadata": {},
   "source": [
    "## üöÄ USAGE EXAMPLE\n",
    "\n",
    "### Basic Extraction:\n",
    "\n",
    "```python\n",
    "# Extract from any file type\n",
    "result = extract_invoice_data('path/to/invoice.xlsx')\n",
    "\n",
    "# Validate\n",
    "validation = validate_extracted_data(result)\n",
    "print(f\"Valid: {validation['valid']}\")\n",
    "\n",
    "# Save to JSON\n",
    "output_file = save_to_json(result)\n",
    "print(f\"Saved to: {output_file}\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "df = convert_to_dataframe(result)\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "### Advanced Usage:\n",
    "\n",
    "```python\n",
    "# Limit rows for large files\n",
    "result = extract_invoice_data('large_invoice.xlsx', max_rows=30)\n",
    "\n",
    "# Custom output path\n",
    "save_to_json(result, 'output/my_invoice.json')\n",
    "\n",
    "# Access specific fields\n",
    "header = result['invoice_header']\n",
    "line_items = result['line_items']\n",
    "print(f\"Vendor: {header['vendor_name']}\")\n",
    "print(f\"Total Items: {len(line_items)}\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PRODUCTION READY - PROCESS YOUR INVOICE\n",
    "# ============================================\n",
    "\n",
    "# USAGE: Update the file_path to your invoice file\n",
    "\n",
    "file_path = 'data/sample_media_invoice.xlsx'  # Change this to your file\n",
    "\n",
    "# Extract invoice data\n",
    "invoice_data = extract_invoice_data(file_path, max_rows=50)\n",
    "\n",
    "# Display results\n",
    "if \"error\" in invoice_data:\n",
    "    print(f\"\\n‚ùå ERROR: {invoice_data['error']}\")\n",
    "    if \"details\" in invoice_data:\n",
    "        print(f\"Details: {invoice_data['details']}\")\n",
    "else:\n",
    "    # Show header\n",
    "    print(\"\\nüìã INVOICE HEADER:\")\n",
    "    print(json.dumps(invoice_data.get(\"invoice_header\", {}), indent=2))\n",
    "    \n",
    "    # Show line items summary\n",
    "    line_items = invoice_data.get(\"line_items\", [])\n",
    "    print(f\"\\nüì¶ LINE ITEMS: {len(line_items)} total\")\n",
    "    \n",
    "    if line_items:\n",
    "        print(\"\\nSample line items:\")\n",
    "        for item in line_items[:3]:\n",
    "            print(f\"  ‚Ä¢ Line {item.get('line_id')}: {item.get('campaign_name', 'N/A')}\")\n",
    "            print(f\"    Revenue: ${item.get('gross_revenue', 0):,.2f}, \" +\n",
    "                  f\"Impressions: {item.get('billed_impressions', 0):,}\")\n",
    "    \n",
    "    # Validate\n",
    "    validation = validate_extracted_data(invoice_data)\n",
    "    print(f\"\\n‚úÖ VALIDATION: {'PASS' if validation['valid'] else 'FAIL'}\")\n",
    "    if validation['errors']:\n",
    "        print(f\"Errors: {validation['errors']}\")\n",
    "    if validation['warnings']:\n",
    "        print(f\"Warnings: {validation['warnings']}\")\n",
    "    \n",
    "    # Save results\n",
    "    output_file = save_to_json(invoice_data)\n",
    "    print(f\"\\nüíæ Saved to: {output_file}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = convert_to_dataframe(invoice_data)\n",
    "    if not df.empty:\n",
    "        print(f\"\\nüìä DataFrame: {len(df)} rows\")\n",
    "        print(\"\\nColumns:\", df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
